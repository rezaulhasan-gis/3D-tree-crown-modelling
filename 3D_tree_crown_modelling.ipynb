{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81c001d-c90a-41c1-8ded-76b41cfe60f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import laspy\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata,UnivariateSpline\n",
    "from scipy.stats import zscore\n",
    "from laspy.compression import LazrsBackend \n",
    "import geopandas as gpd\n",
    "import src.gvl.trunk_utils as utils\n",
    "from scipy.spatial import KDTree, distance,ConvexHull\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon,Point\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63fbd09f-d8fa-4a94-9904-057161bb9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the appropriate directory\n",
    "os.chdir('C:/Users/User/Desktop/Workstation/Internship/Data/LiDAR/AHN4/Tree_Detection_in_Aerial_Point_Clouds/notebooks') #Kavel__186_428_sample_1_reclassified.las\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f88566-d782-44fc-8e42-6386401cd778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 1: read the las file \n",
    "las_file = laspy.read(\"../datasets/AHN4/AMS_subtiles_1000/ahn4_186_428_sample_1.las\", laz_backend=[LazrsBackend()]) #ahn4_186_428_sample_1.las#Kavel__186_428_sample_1_reclassified.las\n",
    "np.unique(las_file.classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ec027a0-b2e1-4aa1-a193-73ab57b74293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Filter ground points (class 2)\n",
    "ground_mask = las_file.classification == 2 #for Kavel_10 class 5 is tree\n",
    "ground_points = np.c_[las_file.x[ground_mask], las_file.y[ground_mask], las_file.z[ground_mask]]\n",
    "\n",
    "# Step 3: Interpolate ground elevation (Digital Elevation Model - DEM)\n",
    "# Define grid for interpolation based on the spatial extent of the LiDAR data\n",
    "grid_x, grid_y = np.meshgrid(\n",
    "    np.linspace(np.min(las_file.x), np.max(las_file.x), 500),\n",
    "    np.linspace(np.min(las_file.y), np.max(las_file.y), 500)\n",
    ")\n",
    "\n",
    "# Interpolate the ground surface (DEM) using griddata\n",
    "grid_z = griddata(ground_points[:, :2], ground_points[:, 2], (grid_x, grid_y), method='linear')\n",
    "\n",
    "# Flatten the grid for easier subtraction later\n",
    "grid_points = np.c_[grid_x.ravel(), grid_y.ravel()]\n",
    "grid_z_flat = grid_z.ravel()\n",
    "\n",
    "# Step 4: Normalize the entire point cloud by subtracting ground elevation\n",
    "all_points = np.c_[las_file.x, las_file.y, las_file.z]\n",
    "normalized_z = las_file.z - griddata(grid_points, grid_z_flat, (las_file.x, las_file.y), method='linear')\n",
    "\n",
    "# Replace the original Z values with the normalized Z values\n",
    "las_file.z = normalized_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4aa05f8-9c26-4f9a-8587-1b5bca192479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter points classified as 'tree'\n",
    "tree_mask = las_file.classification == 5 #for Kavel_10 class 5 is tree\n",
    "\n",
    "# Create a new LAS object with only 'tree' points\n",
    "filtered_las = laspy.LasData(las_file.header)\n",
    "las_file.points = las_file.points[tree_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4a9e760-ee95-4c7a-8c79-5b66bbd44445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(483452, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the file coordinates\n",
    "coord = np.c_[las_file.x, las_file.y, las_file.z]\n",
    "coord.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "425edd9b-ff6a-4077-967c-760f143824ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396468, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(coord)\n",
    "pcd_down = pcd.voxel_down_sample(voxel_size=0.3)\n",
    "coord = np.asarray(pcd_down.points)\n",
    "coord.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d850ee66-c4af-428b-bcb0-4769952d5c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the coordinates by z value\n",
    "position = coord[coord[:, 2].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bed4e8da-c7ab-4179-af2c-2ed0ea1d6a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of \"point\" class for each set of coordinates\n",
    "points = []\n",
    "for i in range(len(position)):\n",
    "    i = utils.Point(i, position[i])\n",
    "    points.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ebdc388-28de-4a03-8995-ed3200c380dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (in meters)\n",
    "r = 3  # radius of the search sphere for the initial clustering\n",
    "radius = 0.8  # the radius on which we count the point density in x and y for each point\n",
    "# (the parameter used for local maxima calculation)\n",
    "window_size = 4 # the size of the search window for local maxima in each cluster\n",
    "max_distance = 7.5  # the delineated trunks radius\n",
    "restrict_d = (\n",
    "    2  # the minimum eucledian distance that 2 peaks of the same cluster can have\n",
    ")\n",
    "small_clusters = 150  # the size of the small custers we suspect as outliers\n",
    "# (won't be deleted, they will just merge with a nearby big cluster if there is any,\n",
    "# else they will be taken as individual clusters)\n",
    "small_outliers = 50 # the minimal cluster size to be allowed as a tree.\n",
    "# Deleting every cluster below this value (optional).\n",
    "diff_height = (\n",
    "    1.5  # the difference in height between 2 clusters very close to each other\n",
    ")\n",
    "# (this is the parameter to take care of branches that are classified as a separate cluster)\n",
    "branch_dist = 0.8  # the max distance a branch cluster can be from the main tree\n",
    "min_dist_tree = (\n",
    "    2  # the max distance of 2 clusters to be checked if they are the same tree\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5529975-7904-4cb5-be14-21ea456270c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all points within distance r of point(s) x\n",
    "tree = scipy.spatial.cKDTree(position)\n",
    "nn = tree.query_ball_point(position, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edc053db-3ad7-4f6d-a1e4-88764d441c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = np.zeros(len(position), dtype=int)\n",
    "centroids = np.zeros((len(position), 3))\n",
    "has_parent = np.zeros(len(position), dtype=bool)\n",
    "\n",
    "# Loop over all points\n",
    "for i, this_nn in enumerate(nn):\n",
    "    # If the point has no neighbors within radius r, it is a tree peak\n",
    "    if len(this_nn) == 1:\n",
    "        links[i] = i\n",
    "        centroids[i] = position[i]\n",
    "        has_parent[i] = True\n",
    "    # If the point has at least one neighbor within radius r\n",
    "    else:\n",
    "        # Find all neighbors with a higher z value\n",
    "        upper_nnbs = [j for j in this_nn if position[j, 2] > position[i, 2]]\n",
    "        # If there are no such neighbors, the point is a tree peak\n",
    "        if not upper_nnbs:\n",
    "            links[i] = i\n",
    "            centroids[i] = position[i]\n",
    "            has_parent[i] = True\n",
    "        # If there are any neighbors with a higher z value\n",
    "        else:\n",
    "            # Calculate the centroid of the group of neighbors\n",
    "            centroids[i] = np.mean(position[upper_nnbs], axis=0)\n",
    "            # Calculate the distances between each neighbor and the centroid\n",
    "            dist = scipy.spatial.distance.cdist(\n",
    "                position[upper_nnbs], [centroids[i]], metric=\"euclidean\"\n",
    "            )\n",
    "            # Find the neighbor closest to the centroid and store its index as a link\n",
    "            links[i] = upper_nnbs[np.argmin(dist)]\n",
    "\n",
    "has_parent = has_parent.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aff69e30-1f9e-4cb8-87cc-db252a864c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "networks = []\n",
    "all_paths = []\n",
    "for p in points:\n",
    "    current_idx = p.index\n",
    "\n",
    "    if len(points[current_idx].paths) == 0:\n",
    "        end = False\n",
    "\n",
    "        # initialize new path\n",
    "        new_path = utils.Path(len(all_paths))  # len paths as index\n",
    "        all_paths.append(new_path)\n",
    "\n",
    "        # add first point to the path\n",
    "        new_path.add_point(points[current_idx])\n",
    "        points[current_idx].add_path(new_path)\n",
    "\n",
    "        # append path\n",
    "        while end is False:\n",
    "            # point has a parent\n",
    "            if has_parent[current_idx] != 1:\n",
    "                # make link\n",
    "                points[current_idx].linked_to = points[links[current_idx]]\n",
    "\n",
    "                if len(points[current_idx].linked_to.paths) == 0:\n",
    "                    # not in path\n",
    "                    points[current_idx].linked_to.add_path(new_path)\n",
    "                    new_path.add_point(points[current_idx].linked_to)\n",
    "                    current_idx = links[current_idx]\n",
    "\n",
    "                else:\n",
    "                    # in path\n",
    "                    points[current_idx].linked_to.network.add_path(new_path)\n",
    "                    points[current_idx].add_path(new_path)\n",
    "                    points[current_idx].linked_to.add_path(new_path)\n",
    "                    end = True\n",
    "\n",
    "            # point has no parent\n",
    "            # make network, end path\n",
    "            else:\n",
    "                points[current_idx].linked_to = points[current_idx]\n",
    "                # init new network\n",
    "                new_network = utils.Network(len(networks))  # len networks as index\n",
    "                new_network.add_path(\n",
    "                    new_path\n",
    "                )  # path and points are assigned to network\n",
    "                new_network.top = current_idx\n",
    "                new_network.points = new_path.points  # add points to the network\n",
    "                networks.append(new_network)\n",
    "                points[current_idx].network = new_network\n",
    "                end = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fce379-841d-4c32-97cb-0c0555df8aa5",
   "metadata": {},
   "source": [
    "4. Remove all the outlier clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74c5b7cb-1234-4664-b7a9-2987d143274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array to extract and store all our individual tree labels from\n",
    "labels = np.zeros(len(points))\n",
    "\n",
    "# Extract the label value from class network to our new built array\n",
    "for p in points:\n",
    "    labels[p.index] = p.network.index\n",
    "labels = labels.astype(\"int\")\n",
    "\n",
    "array_test = np.column_stack((position, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bb11c2f-b762-46ff-9429-4ef105f9de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of each cluster label\n",
    "labels_new = array_test[:, 3]\n",
    "array = array_test[:, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07631cf6-a76d-4407-b6a2-259f7bb17a66",
   "metadata": {},
   "source": [
    "Remove clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbb0d8b6-a680-490c-87a0-669ea67043cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the count of each label\n",
    "unique, counts = np.unique(labels_new, return_counts=True)\n",
    "label_count = dict(zip(unique, counts))\n",
    "\n",
    "# Initialize an empty list to store the indices of the large clusters\n",
    "large_cluster_indices = []\n",
    "\n",
    "# Iterate through the cluster labels\n",
    "for i, label in enumerate(labels_new):\n",
    "    # If the label corresponds to a large cluster, add the index to the list\n",
    "    if label_count.get(label, 0) >= 10:\n",
    "        large_cluster_indices.append(i)\n",
    "\n",
    "# Use the indices of the large clusters to create a new array\n",
    "array_test = array[large_cluster_indices, :]\n",
    "\n",
    "# Add the labels as the last column of the new array\n",
    "array_test = np.column_stack((array_test, labels_new[large_cluster_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bfd4ce-19da-439c-a4ec-b81854eee265",
   "metadata": {},
   "source": [
    "5. Fix the small clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f2689b1-5329-4a30-9d60-2da4ba54a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the array for the \"fix small clusters\" code\n",
    "labels_2 = array_test[:, 3].astype(\"int\")\n",
    "labels33, point_count33 = np.unique(labels_2, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc157228-c5b6-4d94-88a0-a84a94a84f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterating_array = []\n",
    "for i in range(len(labels33)):\n",
    "    if point_count33[i] <= small_clusters:\n",
    "        iterating_array.append(labels33[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "accd1a9b-88b1-409b-a854-629c2b80de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get centroids of all clusters in the dataset\n",
    "all_centroids = []\n",
    "all_labs = []\n",
    "for label in np.unique(array_test[:, 3]):\n",
    "    centroid = array_test[array_test[:, 3] == label, :2].mean(axis=0)\n",
    "    all_centroids.append(centroid)\n",
    "    all_labs.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "941b82a9-51fe-4f1a-ba4c-cdb2b44778fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the pairs of the closest clusters\n",
    "tree1 = KDTree(all_centroids)\n",
    "\n",
    "labels_nn = []\n",
    "for i in range(len(all_labs)):\n",
    "    point_cent = all_centroids[i]\n",
    "    dist, idx = tree1.query(point_cent, k=2)\n",
    "    closest_idx = idx[1] if idx[0] == i else idx[0]\n",
    "    labels_nn.append([all_labs[i], all_labs[closest_idx]])\n",
    "\n",
    "# Filter the list so it contains only the small clusters that we will fix\n",
    "filtered_list = [x for x in labels_nn if int(x[0]) in iterating_array]\n",
    "array_test2 = array_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e87e402-0f5e-4dd2-83bd-f07b70444c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in filtered_list:\n",
    "    coord_xy = array_test2[array_test2[:, 3] == i[0]]\n",
    "    coord_xy2 = array_test2[array_test2[:, 3] == i[1]]\n",
    "    wk = distance.cdist(coord_xy[:, :2], coord_xy2[:, :2], \"euclidean\")\n",
    "    z = abs(coord_xy[:, 2:3].min() - coord_xy[:, 2:3].min())\n",
    "    kk = array_test2[:, 2][array_test2[:, 3] == i[1]]\n",
    "    z = abs(coord_xy[:, 2:3].min() - kk.min())\n",
    "    if (\n",
    "        len(array_test2[array_test2 == i[0]]) < (small_clusters / 2)\n",
    "        and wk.min() < min_dist_tree\n",
    "    ):\n",
    "        array_test[:, 3][array_test[:, 3] == i[0]] = i[1]\n",
    "    if wk.min() < branch_dist and z > diff_height:\n",
    "        array_test[:, 3][array_test[:, 3] == i[0]] = i[1]\n",
    "    if (\n",
    "        len(array_test2[array_test2 == i[0]]) < small_clusters\n",
    "        and wk.min() < min_dist_tree / 2\n",
    "    ):\n",
    "        array_test[:, 3][array_test[:, 3] == i[0]] = i[1]\n",
    "    coord_xy = []\n",
    "    coord_xy2 = []\n",
    "    wk = []\n",
    "    ind = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613fc0fd-7eb9-4fc0-9624-cb7063657ada",
   "metadata": {},
   "source": [
    "Delete small clusters (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f9ae97b-bd7d-4551-9715-9092b784eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of each cluster label\n",
    "labels_new = array_test[:, 3]\n",
    "array = array_test[:, 0:3]\n",
    "\n",
    "# Create a dictionary to store the count of each label\n",
    "unique, counts = np.unique(labels_new, return_counts=True)\n",
    "label_count = dict(zip(unique, counts))\n",
    "\n",
    "# Initialize an empty list to store the indices of the large clusters\n",
    "large_cluster_indices = []\n",
    "\n",
    "# Iterate through the cluster labels\n",
    "for i, label in enumerate(labels_new):\n",
    "    # If the label corresponds to a large cluster, add the index to the list\n",
    "    if label_count.get(label, 0) >= small_outliers:\n",
    "        large_cluster_indices.append(i)\n",
    "\n",
    "# Use the indices of the large clusters to create a new array\n",
    "array_test = array[large_cluster_indices, :]\n",
    "\n",
    "# Add the labels as the last column of the new array\n",
    "array_test = np.column_stack((array_test, labels_new[large_cluster_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed404a6-1ed5-488a-aefd-95c82b6b520b",
   "metadata": {},
   "source": [
    "6. Get the number of points in buffer per point (the local maxima column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3b7d24b-4f7e-40c3-b906-c53e939fb85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "points = array_test[:, :2]\n",
    "\n",
    "# Create KDTree from points\n",
    "kd_tree = KDTree(points)\n",
    "\n",
    "# Array to store the number of points in the buffer for each point\n",
    "count = np.zeros(len(points), dtype=int)\n",
    "\n",
    "# Loop over each point and find points in the buffer\n",
    "for i, p in enumerate(points):\n",
    "    idx = kd_tree.query_ball_point(p, radius)\n",
    "    count[i] = len(idx) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf57d63-6b3c-47dd-8098-7a02cde1e7ea",
   "metadata": {},
   "source": [
    "7. Find the trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "632ccae6-348b-45e0-87ee-ca2acb19dc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_local_maxima(full_array, window_size, max_distance, restrict_d):\n",
    "    # get the unique label of tree clusters\n",
    "    unique_clusters = np.unique(full_array[:, 3])\n",
    "    current_label = 1\n",
    "    labels = np.zeros(full_array.shape[0], dtype=np.int64)\n",
    "    full_array = np.column_stack((full_array, labels))\n",
    "    iteration = 0\n",
    "    # Iterate through every single tree cluster separately\n",
    "    for cluster_id in unique_clusters:\n",
    "        peaks1 = []\n",
    "        dist_peaks = 100\n",
    "        # Form an array for the cluster of this iteration\n",
    "        kot_arr = full_array[full_array[:, 3] == cluster_id]\n",
    "        x1 = kot_arr[:, 0]\n",
    "        y1 = kot_arr[:, 1]\n",
    "        z1 = kot_arr[:, 2]\n",
    "        p1 = kot_arr[:, 4]\n",
    "        labels_k = kot_arr[:, 5]\n",
    "        # Now we iterate through each point of the cluster of this iteration\n",
    "        for i in range(len(kot_arr)):\n",
    "            # We form a search window around each point of the cluster\n",
    "            x_min = x1[i] - window_size\n",
    "            x_max = x1[i] + window_size\n",
    "            y_min = y1[i] - window_size\n",
    "            y_max = y1[i] + window_size\n",
    "            in_window = np.bitwise_and(x1 >= x_min, x1 <= x_max)\n",
    "            in_window = np.bitwise_and(\n",
    "                in_window, np.bitwise_and(y1 >= y_min, y1 <= y_max)\n",
    "            )\n",
    "            in_window = np.bitwise_and(in_window, kot_arr[:, 3] == cluster_id)\n",
    "\n",
    "            # Calculate and save the distances between the local maximas we find.\n",
    "            if len(peaks1) > 0:\n",
    "                this_point = [x1[i], y1[i]]\n",
    "                peak_array = np.array(peaks1)\n",
    "                this_point = np.array(this_point)\n",
    "                this_point = this_point.reshape(1, 2)\n",
    "                dist_peaks = distance.cdist(peak_array, this_point, \"euclidean\")\n",
    "\n",
    "            # We find the local maximas for each window\n",
    "            # Then we restric every local maximas that are way too close with each other with\n",
    "            # the parameter \"restrict_d\". Then the local maximas with an accepted distace between\n",
    "            # each other are relabeld as a unique number for each unique tree.\n",
    "            if np.max(p1[in_window]) == p1[i] and np.min(dist_peaks) > restrict_d:\n",
    "                peaks1.append([x1[i], y1[i]])\n",
    "                points_to_label = np.argwhere(\n",
    "                    np.logical_and(\n",
    "                        np.abs(x1 - x1[i]) <= max_distance,\n",
    "                        np.abs(y1 - y1[i]) <= max_distance,\n",
    "                    )\n",
    "                )\n",
    "                points_to_label = points_to_label.flatten()\n",
    "                if labels_k[i] == 0:\n",
    "                    labels_k[points_to_label] = current_label\n",
    "                    current_label += 1\n",
    "                else:\n",
    "                    labels_k[points_to_label] = labels_k[i]\n",
    "\n",
    "        # we create a new array with the new labels for trunks\n",
    "        new_2 = np.c_[x1, y1, z1, labels_k]\n",
    "        if iteration == 0:\n",
    "            final_result = new_2\n",
    "        else:\n",
    "            final_result = np.vstack((final_result, new_2))\n",
    "        iteration = 1\n",
    "\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6590be6-15b2-4e1c-9115-ae2e077bbbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find trees\n",
    "full_array = np.column_stack((array_test, count))\n",
    "Final_labels = cluster_local_maxima(full_array, window_size, max_distance, restrict_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c2c23e0-4b48-4549-9925-69494b41f657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 742 trees in this area\n"
     ]
    }
   ],
   "source": [
    "# Get the number of trees in this las file\n",
    "tree_count = np.unique(Final_labels[:, 3])\n",
    "print(\"there are\", len(tree_count), \"trees in this area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cbe7167-5467-4ed9-98ac-56877c10ef93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize a list to hold the geometries for visualization\n",
    "geometries = []\n",
    "\n",
    "# Get the unique cluster labels\n",
    "unique_labels = np.unique(Final_labels[:, 3])\n",
    "\n",
    "# Iterate over each unique cluster label\n",
    "for label in unique_labels:\n",
    "    # Extract points belonging to the current cluster\n",
    "    cluster_points = Final_labels[Final_labels[:, 3] == label][:, :3]\n",
    "    \n",
    "    # Create an Open3D point cloud object for the cluster\n",
    "    cluster_pcd = o3d.geometry.PointCloud()\n",
    "    cluster_pcd.points = o3d.utility.Vector3dVector(cluster_points)\n",
    "    \n",
    "    # Assign a random color to the cluster\n",
    "    cluster_pcd.paint_uniform_color(np.random.rand(3))\n",
    "    \n",
    "    # Add the point cloud to the list of geometries\n",
    "    geometries.append(cluster_pcd)\n",
    "    \n",
    "    # Create and add the bounding box for the cluster\n",
    "    bbox = cluster_pcd.get_axis_aligned_bounding_box()\n",
    "    bbox.color = (0, 0, 0)  # Set bounding box color (black)\n",
    "    geometries.append(bbox)\n",
    "\n",
    "# Visualize all clusters and their bounding boxes\n",
    "o3d.visualization.draw_geometries(geometries, window_name='Clustered Trees with Bounding Boxes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2001b2b2-6ae5-469d-ad07-0e0133550297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now calculate tree properties\n",
    "segmented_trees = [Final_labels[Final_labels[:, 3] == label][:, :3] for label in unique_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f1e8bd-c47a-402c-a93a-b079197380db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Tree Top Location X (m)  Tree Top Location Y (m)  Tree Top Height (m)  \\\n",
      "0                186929.2380               428420.822              24.0450   \n",
      "1                186967.7940               428423.854              28.2310   \n",
      "2                186992.1030               428457.677               6.4240   \n",
      "3                186982.8110               428431.644               5.3040   \n",
      "4                186725.7110               428005.367               4.2910   \n",
      "..                       ...                      ...                  ...   \n",
      "289              186922.1460               428426.782              19.0940   \n",
      "290              186942.8260               428418.781              27.2390   \n",
      "291              186675.8470               428052.045              19.1140   \n",
      "292              186963.9515               428415.981              27.6125   \n",
      "293              186862.6190               428458.375              27.5710   \n",
      "\n",
      "     Canopy Base Height (CBH) (m)  Crown Area (sq m)  Crown Diameter (m)  \\\n",
      "0                          6.7870        1671.050606           46.126432   \n",
      "1                         14.6100          29.310278            6.108928   \n",
      "2                          3.9430          15.717107            4.473437   \n",
      "3                          3.9460          31.997392            6.382816   \n",
      "4                          3.3645          10.586967            3.671477   \n",
      "..                            ...                ...                 ...   \n",
      "289                       13.6890          31.409327            6.323891   \n",
      "290                       12.9400          27.608100            5.928889   \n",
      "291                       14.6980          21.733390            5.260400   \n",
      "292                       17.1330          18.056788            4.794853   \n",
      "293                       23.6125          20.170088            5.067677   \n",
      "\n",
      "     Crown Volume (cubic m)  \n",
      "0               3334.486277  \n",
      "1                348.548029  \n",
      "2                 46.489699  \n",
      "3                 36.307866  \n",
      "4                 14.248688  \n",
      "..                      ...  \n",
      "289              143.175492  \n",
      "290              355.113835  \n",
      "291               97.305294  \n",
      "292              210.476922  \n",
      "293               84.028810  \n",
      "\n",
      "[294 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Filter out clusters that have fewer than 10 points\n",
    "segmented_trees = [tree for tree in segmented_trees if tree.shape[0] >= 10]\n",
    "\n",
    "def calculate_tree_top_height_and_location(tree_points):\n",
    "    \"\"\"\n",
    "    Calculate the tree top height and location from a point cloud.\n",
    "    \"\"\"\n",
    "    max_index = np.argmax(tree_points[:, 2])\n",
    "    tree_top_height = tree_points[max_index, 2]\n",
    "    tree_top_location = (tree_points[max_index, 0], tree_points[max_index, 1])\n",
    "    \n",
    "    return tree_top_height, tree_top_location\n",
    "\n",
    "def calculate_crown_area(tree_points):\n",
    "    \"\"\"\n",
    "    Calculate the crown area of a tree from its point cloud using a convex hull.\n",
    "    \"\"\"\n",
    "    xy_points = tree_points[:, :2]\n",
    "    \n",
    "    if len(np.unique(xy_points, axis=0)) < 3:\n",
    "        return 0\n",
    "    \n",
    "    hull = ConvexHull(xy_points)\n",
    "    crown_area = hull.area\n",
    "    \n",
    "    return crown_area\n",
    "\n",
    "def calculate_crown_diameter(crown_area):\n",
    "    \"\"\"\n",
    "    Calculate the crown diameter given the crown area, assuming a circular shape.\n",
    "    \"\"\"\n",
    "    crown_diameter = 2 * np.sqrt(crown_area / np.pi)\n",
    "    return crown_diameter\n",
    "\n",
    "def estimate_cbh(tree, plot=False):\n",
    "    z_values = tree[:, 2]\n",
    "    if len(z_values) < 4:\n",
    "        return None\n",
    "\n",
    "    sorted_indices = np.argsort(z_values)\n",
    "    z_values_sorted = z_values[sorted_indices]\n",
    "    \n",
    "    percentile_ranking = np.linspace(0, 1, len(z_values_sorted))\n",
    "    \n",
    "    spline = UnivariateSpline(z_values_sorted, percentile_ranking, s=len(percentile_ranking))\n",
    "    smoothed_curve = spline(z_values_sorted)\n",
    "    \n",
    "    first_derivative = spline.derivative(n=1)(z_values_sorted)\n",
    "    second_derivative = spline.derivative(n=2)(z_values_sorted)\n",
    "    \n",
    "    inflection_points = np.where(np.diff(np.sign(second_derivative)))[0]\n",
    "    valid_inflection_points = [i for i in inflection_points if percentile_ranking[i] < 0.5]\n",
    "    \n",
    "    if not valid_inflection_points:\n",
    "        return None\n",
    "    \n",
    "    cbh_index = valid_inflection_points[np.argmax(first_derivative[valid_inflection_points])]\n",
    "    cbh_height = z_values_sorted[cbh_index]\n",
    "    \n",
    "    second_quartile_height = np.percentile(z_values_sorted, 50)\n",
    "    if cbh_height >= second_quartile_height:\n",
    "        return None\n",
    "    \n",
    "    if plot:\n",
    "        plot_percentile_profile(z_values_sorted, percentile_ranking, smoothed_curve, first_derivative, second_derivative, valid_inflection_points)\n",
    "    \n",
    "    return cbh_height\n",
    "\n",
    "def calculate_ellipsoidal_volume(height, diameter):\n",
    "    volume = (4/3) * np.pi * diameter * height\n",
    "    return volume\n",
    "\n",
    "# Initialize lists to collect data\n",
    "tree_top_heights = []\n",
    "tree_top_locations = []\n",
    "cbh_heights = []\n",
    "crown_areas = []\n",
    "crown_diameters = []\n",
    "crown_volumes = []\n",
    "\n",
    "# Iterate over each tree and calculate properties\n",
    "for tree_points in segmented_trees:\n",
    "    # Calculate Tree Top Height and Location\n",
    "    tree_top_height, tree_top_location = calculate_tree_top_height_and_location(tree_points)\n",
    "    \n",
    "    # Calculate CBH\n",
    "    cbh_height = estimate_cbh(tree_points)\n",
    "    if cbh_height is None:\n",
    "        continue  # Skip this tree if CBH could not be estimated\n",
    "    \n",
    "    # Calculate Tree Crown Area\n",
    "    crown_area = calculate_crown_area(tree_points)\n",
    "    \n",
    "    # Calculate Tree Crown Diameter\n",
    "    crown_diameter = calculate_crown_diameter(crown_area)\n",
    "    \n",
    "    # Calculate the Crown Height\n",
    "    crown_height = tree_top_height - cbh_height\n",
    "    \n",
    "    # Calculate Crown Volume\n",
    "    crown_volume = calculate_ellipsoidal_volume(crown_height, crown_diameter)\n",
    "    \n",
    "    # Append results\n",
    "    tree_top_heights.append(tree_top_height)\n",
    "    tree_top_locations.append(tree_top_location)\n",
    "    cbh_heights.append(cbh_height)\n",
    "    crown_areas.append(crown_area)\n",
    "    crown_diameters.append(crown_diameter)\n",
    "    crown_volumes.append(crown_volume)\n",
    "\n",
    "# Ensure all lists have the same length\n",
    "num_trees = len(tree_top_heights)\n",
    "assert len(tree_top_locations) == num_trees\n",
    "assert len(cbh_heights) == num_trees\n",
    "assert len(crown_areas) == num_trees\n",
    "assert len(crown_diameters) == num_trees\n",
    "assert len(crown_volumes) == num_trees\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "tree_data = pd.DataFrame({\n",
    "    'Tree Top Location X (m)': [loc[0] for loc in tree_top_locations],\n",
    "    'Tree Top Location Y (m)': [loc[1] for loc in tree_top_locations],\n",
    "    'Tree Top Height (m)': tree_top_heights,\n",
    "    'Canopy Base Height (CBH) (m)': cbh_heights,\n",
    "    'Crown Area (sq m)': crown_areas,\n",
    "    'Crown Diameter (m)': crown_diameters,\n",
    "    'Crown Volume (cubic m)': crown_volumes\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(tree_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b117f7d0-7eba-4edb-999a-569ba9eca13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile of tree crowns created at: tree_crowns_AHN4.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14832\\1551039068.py:56: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf_crowns.to_file(output_shapefile)\n",
      "C:\\Users\\User\\anaconda3\\envs\\tree\\lib\\site-packages\\pyogrio\\raw.py:709: RuntimeWarning: Normalized/laundered field name: 'Tree Top Height (m)' to 'Tree Top H'\n",
      "  ogr_write(\n",
      "C:\\Users\\User\\anaconda3\\envs\\tree\\lib\\site-packages\\pyogrio\\raw.py:709: RuntimeWarning: Normalized/laundered field name: 'Crown Area (sq m)' to 'Crown Area'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "def calculate_crown_area_polygon(tree_points):\n",
    "    \"\"\"Calculate the crown area as a polygon using the convex hull of the tree's 2D projection.\"\"\"\n",
    "    # Extract the x, y coordinates for the 2D projection\n",
    "    xy_points = tree_points[:, :2]\n",
    "    \n",
    "    # Calculate the convex hull\n",
    "    hull = ConvexHull(xy_points)\n",
    "    \n",
    "    # Create a polygon from the convex hull vertices\n",
    "    hull_points = xy_points[hull.vertices]\n",
    "    crown_polygon = Polygon(hull_points)\n",
    "    \n",
    "    return crown_polygon\n",
    "\n",
    "# Prepare lists to store the results\n",
    "crown_polygons = []\n",
    "tree_top_heights = []\n",
    "cbh_heights = []\n",
    "crown_areas = []\n",
    "\n",
    "# Iterate over all segmented trees\n",
    "for tree_points in segmented_trees:\n",
    "    # Calculate Tree Top Height\n",
    "    tree_top_height, _ = calculate_tree_top_height_and_location(tree_points)\n",
    "    tree_top_heights.append(tree_top_height)\n",
    "    \n",
    "    # # Estimate Canopy Base Height (CBH)\n",
    "    # cbh_height = estimate_crown_base_height(tree_points)\n",
    "    # cbh_heights.append(cbh_height)\n",
    "    \n",
    "    # Calculate Tree Crown Area Polygon\n",
    "    crown_polygon = calculate_crown_area_polygon(tree_points)\n",
    "    crown_polygons.append(crown_polygon)\n",
    "    \n",
    "    # Calculate Crown Area\n",
    "    crown_areas.append(crown_polygon.area)\n",
    "\n",
    "# Create a GeoDataFrame to store the crown polygons and attributes\n",
    "gdf_crowns = gpd.GeoDataFrame({\n",
    "    'Tree Top Height (m)': tree_top_heights,\n",
    "    'Crown Area (sq m)': crown_areas,\n",
    "    'geometry': crown_polygons\n",
    "})\n",
    "\n",
    "# Set the CRS to EPSG:7415 - Amersfoort / RD New + NAP height\n",
    "gdf_crowns.set_crs(epsg=7415, inplace=True)\n",
    "\n",
    "# Save the GeoDataFrame as a shapefile\n",
    "output_shapefile = \"tree_crowns_AHN4.shp\"\n",
    "gdf_crowns.to_file(output_shapefile)\n",
    "\n",
    "print(f\"Shapefile of tree crowns created at: {output_shapefile}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb130e4-84ba-4d81-9994-5229a1516a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile created at: tree_tops_AHN4.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14832\\3971038371.py:15: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf.to_file(output_shapefile)\n",
      "C:\\Users\\User\\anaconda3\\envs\\tree\\lib\\site-packages\\pyogrio\\raw.py:709: RuntimeWarning: Normalized/laundered field name: 'Tree Top Location X (m)' to 'Tree Top L'\n",
      "  ogr_write(\n",
      "C:\\Users\\User\\anaconda3\\envs\\tree\\lib\\site-packages\\pyogrio\\raw.py:709: RuntimeWarning: Normalized/laundered field name: 'Tree Top Location Y (m)' to 'Tree Top_1'\n",
      "  ogr_write(\n",
      "C:\\Users\\User\\anaconda3\\envs\\tree\\lib\\site-packages\\pyogrio\\raw.py:709: RuntimeWarning: Normalized/laundered field name: 'Tree Top Height (m)' to 'Tree Top H'\n",
      "  ogr_write(\n",
      "C:\\Users\\User\\anaconda3\\envs\\tree\\lib\\site-packages\\pyogrio\\raw.py:709: RuntimeWarning: Normalized/laundered field name: 'Canopy Base Height (CBH) (m)' to 'Canopy Bas'\n",
      "  ogr_write(\n",
      "C:\\Users\\User\\anaconda3\\envs\\tree\\lib\\site-packages\\pyogrio\\raw.py:709: RuntimeWarning: Normalized/laundered field name: 'Crown Area (sq m)' to 'Crown Area'\n",
      "  ogr_write(\n",
      "C:\\Users\\User\\anaconda3\\envs\\tree\\lib\\site-packages\\pyogrio\\raw.py:709: RuntimeWarning: Normalized/laundered field name: 'Crown Diameter (m)' to 'Crown Diam'\n",
      "  ogr_write(\n",
      "C:\\Users\\User\\anaconda3\\envs\\tree\\lib\\site-packages\\pyogrio\\raw.py:709: RuntimeWarning: Normalized/laundered field name: 'Crown Volume (cubic m)' to 'Crown Volu'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create geometries for the GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(tree_data['Tree Top Location X (m)'], tree_data['Tree Top Location Y (m)'])]\n",
    "\n",
    "# Create a GeoDataFrame with the updated column order\n",
    "gdf = gpd.GeoDataFrame(tree_data, geometry=geometry)\n",
    "\n",
    "# Set the CRS to EPSG:7415 - Amersfoort / RD New + NAP height\n",
    "gdf.set_crs(epsg=7415, inplace=True)\n",
    "\n",
    "# Save the GeoDataFrame as a shapefile\n",
    "output_shapefile = \"tree_tops_AHN4.shp\"\n",
    "gdf.to_file(output_shapefile)\n",
    "\n",
    "print(f\"Shapefile created at: {output_shapefile}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
